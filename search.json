[
  {
    "objectID": "decision tree.html",
    "href": "decision tree.html",
    "title": "Play Tennis",
    "section": "",
    "text": "# numpy and pandas initialization\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n\n#Loading the PlayTennis data\nplaytennis = pd.read_csv(\"playtennis.csv\")\n\n\nplaytennis.head(5)\n\n\n\n\n\n\n\n\noutlook\ntemp\nhumidity\nwindy\nplay\n\n\n\n\n0\nsunny\nhot\nhigh\nFalse\nno\n\n\n1\nsunny\nhot\nhigh\nTrue\nno\n\n\n2\novercast\nhot\nhigh\nFalse\nyes\n\n\n3\nrainy\nmild\nhigh\nFalse\nyes\n\n\n4\nrainy\ncool\nnormal\nFalse\nyes\n\n\n\n\n\n\n\n\nplaytennis['humidity'].hist()\n\n\n\n\n\n\n\n\n\nplaytennis['outlook'].hist()\n\n\n\n\n\n\n\n\n\nplaytennis['play'].hist()\n\n\n\n\n\n\n\n\n\n #get unique labels\nprint(playtennis['outlook'].unique())\nprint(playtennis['temp'].unique())\nprint(playtennis['humidity'].unique())\nprint(playtennis['windy'].unique())\nprint(playtennis['play'].unique())\n\n['sunny' 'overcast' 'rainy']\n['hot' 'mild' 'cool']\n['high' 'normal']\n[False  True]\n['no' 'yes']\n\n\n\n#using label encoder\nfrom sklearn.preprocessing import LabelEncoder\nLe = LabelEncoder() #each categorical value is assigned a numerical value(0,1,2...)\nplaytennis['outlook'] = Le.fit_transform(playtennis['outlook'])\nplaytennis['temp'] = Le.fit_transform(playtennis['temp'])\nplaytennis['humidity'] = Le.fit_transform(playtennis['humidity'])\nplaytennis['windy'] = Le.fit_transform(playtennis['windy'])\nplaytennis['play'] = Le.fit_transform(playtennis['play'])\n\n\n#After applying label encoding, each unique column labels is converted into unique numerical values between 0 to number of labels in each column\n#each value represent a unique label e.g in \"outlook\" column 2 is the label for \"sunny\", 0 is the label for \"overcast\", and 1 is a label for \"rainy\".\nprint(playtennis['outlook'].unique())\nprint(playtennis['temp'].unique())\nprint(playtennis['humidity'].unique())\nprint(playtennis['windy'].unique())\nprint(playtennis['play'].unique())\n\n[2 0 1]\n[1 2 0]\n[0 1]\n[0 1]\n[0 1]\n\n\n\nplaytennis\n\n\n\n\n\n\n\n\noutlook\ntemp\nhumidity\nwindy\nplay\n\n\n\n\n0\n2\n1\n0\n0\n0\n\n\n1\n2\n1\n0\n1\n0\n\n\n2\n0\n1\n0\n0\n1\n\n\n3\n1\n2\n0\n0\n1\n\n\n4\n1\n0\n1\n0\n1\n\n\n5\n1\n0\n1\n1\n0\n\n\n6\n0\n0\n1\n1\n1\n\n\n7\n2\n2\n0\n0\n0\n\n\n8\n2\n0\n1\n0\n1\n\n\n9\n1\n2\n1\n0\n1\n\n\n10\n2\n2\n1\n1\n1\n\n\n11\n0\n2\n0\n1\n1\n\n\n12\n0\n1\n1\n0\n1\n\n\n13\n1\n2\n0\n1\n0\n\n\n\n\n\n\n\n\ny = playtennis['play'] #decision column\nx = playtennis.drop(['play'],axis=1) #dropping\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test  = train_test_split(x,y,test_size = 0.2) #split the data\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\n\n# building decision tree\nclf=DecisionTreeClassifier()\nclf=clf.fit(x_train,y_train)\ny_pred=clf.predict(x_test)\n\n\nprint(\"Accuracy:\", metrics.accuracy_score(y_test,y_pred))\n\nAccuracy: 0.6666666666666666\n\n\n\ndef predict_play():\n    Le = LabelEncoder()\n\n    outlook = \"sunny\"\n    temp = \"cool\"\n    humidity = \"normal\"\n    windy = \"True\"\n\n    windy = True if windy.lower() == 'true' else False\n\n    user_input = pd.DataFrame({'outlook': [outlook],\n                               'temp' : [temp],\n                               'humidity': [humidity],\n                               'windy' : [windy]})\n    for column in x.columns : \n        user_input[column] = Le.fit_transform(user_input[column])\n    prediction = clf.predict(user_input)\n    prediction = \"yes\" if prediction[0] == 1 else \"no\"\n    print(\"Based on the conditiond, should you play tennis?\", prediction)\npredict_play()\n\nBased on the conditiond, should you play tennis? yes\n\n\n\n!pip install dtreeviz\n\nDefaulting to user installation because normal site-packages is not writeable\nCollecting dtreeviz\n  Downloading dtreeviz-2.2.2-py3-none-any.whl (91 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/91.8 KB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.8/91.8 KB 4.8 MB/s eta 0:00:00\nCollecting pytest\n  Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/342.3 KB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 342.3/342.3 KB 37.4 MB/s eta 0:00:00\nRequirement already satisfied: numpy in /home/runner/.local/lib/python3.10/site-packages (from dtreeviz) (2.1.3)\nRequirement already satisfied: scikit-learn in /home/runner/.local/lib/python3.10/site-packages (from dtreeviz) (1.5.2)\nCollecting colour\n  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: pandas in /home/runner/.local/lib/python3.10/site-packages (from dtreeviz) (2.2.3)\nRequirement already satisfied: matplotlib in /home/runner/.local/lib/python3.10/site-packages (from dtreeviz) (3.9.2)\nCollecting graphviz&gt;=0.9\n  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/47.1 KB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.1/47.1 KB 4.2 MB/s eta 0:00:00\nRequirement already satisfied: fonttools&gt;=4.22.0 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (4.55.0)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;dtreeviz) (24.2)\nRequirement already satisfied: cycler&gt;=0.10 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (0.12.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (1.4.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib-&gt;dtreeviz) (2.4.7)\nRequirement already satisfied: pillow&gt;=8 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (11.0.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (2.9.0.post0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /home/runner/.local/lib/python3.10/site-packages (from matplotlib-&gt;dtreeviz) (1.3.1)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/lib/python3/dist-packages (from pandas-&gt;dtreeviz) (2022.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/runner/.local/lib/python3.10/site-packages (from pandas-&gt;dtreeviz) (2024.2)\nCollecting iniconfig\n  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\nRequirement already satisfied: tomli&gt;=1 in /usr/local/lib/python3.10/dist-packages (from pytest-&gt;dtreeviz) (2.1.0)\nCollecting pluggy&lt;2,&gt;=1.5\n  Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: exceptiongroup&gt;=1.0.0rc8 in /home/runner/.local/lib/python3.10/site-packages (from pytest-&gt;dtreeviz) (1.2.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in /home/runner/.local/lib/python3.10/site-packages (from scikit-learn-&gt;dtreeviz) (3.5.0)\nRequirement already satisfied: scipy&gt;=1.6.0 in /home/runner/.local/lib/python3.10/site-packages (from scikit-learn-&gt;dtreeviz) (1.14.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in /home/runner/.local/lib/python3.10/site-packages (from scikit-learn-&gt;dtreeviz) (1.4.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/lib/python3/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;dtreeviz) (1.16.0)\nInstalling collected packages: colour, pluggy, iniconfig, graphviz, pytest, dtreeviz\nSuccessfully installed colour-0.1.5 dtreeviz-2.2.2 graphviz-0.20.3 iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.3\n\n\n\nfrom sklearn import tree\n\n\nfrom dtreeviz.trees import *\n\n\ntext_representation = tree.export_text(clf)\nprint(text_representation)\n\n|--- feature_0 &lt;= 0.50\n|   |--- class: 1\n|--- feature_0 &gt;  0.50\n|   |--- feature_2 &lt;= 0.50\n|   |   |--- class: 0\n|   |--- feature_2 &gt;  0.50\n|   |   |--- feature_3 &lt;= 0.50\n|   |   |   |--- class: 1\n|   |   |--- feature_3 &gt;  0.50\n|   |   |   |--- feature_1 &lt;= 1.00\n|   |   |   |   |--- class: 0\n|   |   |   |--- feature_1 &gt;  1.00\n|   |   |   |   |--- class: 1\n\n\n\n\nfig = plt.figure(figsize=(7,8))\ntree.plot_tree(clf, feature_names=x.columns, class_names=['yes', 'no'], filled=True)\n\n[Text(0.2857142857142857, 0.9, 'outlook &lt;= 0.5\\ngini = 0.463\\nsamples = 11\\nvalue = [4, 7]\\nclass = no'),\n Text(0.14285714285714285, 0.7, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\\nclass = no'),\n Text(0.21428571428571427, 0.8, 'True  '),\n Text(0.42857142857142855, 0.7, 'humidity &lt;= 0.5\\ngini = 0.5\\nsamples = 8\\nvalue = [4, 4]\\nclass = yes'),\n Text(0.3571428571428571, 0.8, '  False'),\n Text(0.2857142857142857, 0.5, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\\nclass = yes'),\n Text(0.5714285714285714, 0.5, 'windy &lt;= 0.5\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]\\nclass = no'),\n Text(0.42857142857142855, 0.3, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\\nclass = no'),\n Text(0.7142857142857143, 0.3, 'temp &lt;= 1.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]\\nclass = yes'),\n Text(0.5714285714285714, 0.1, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]\\nclass = yes'),\n Text(0.8571428571428571, 0.1, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]\\nclass = no')]",
    "crumbs": [
      "Bermain Tennis"
    ]
  },
  {
    "objectID": "table.html",
    "href": "table.html",
    "title": "Tempat Belajar Coding",
    "section": "",
    "text": "No.\nNama File\n\n\n\n\n\n\n\nplay tennis\n\n\n\n\n\ntitanic\n\n\n\n\n\nprakiraan cuaca",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "weather.html",
    "href": "weather.html",
    "title": "Prakiraan cuaca",
    "section": "",
    "text": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/0 (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\n%matplotlib inline\n\n\ndata = pd.read_csv('weather.csv')\n\n\ndata\n\n\n\n\n\n\n\n\nDate\nLocation\nMinTemp\nMaxTemp\nRainfall\nEvaporation\nSunshine\nWindGustDir\nWindGustSpeed\nWindDir9am\n...\nHumidity9am\nHumidity3pm\nPressure9am\nPressure3pm\nCloud9am\nCloud3pm\nTemp9am\nTemp3pm\nRainToday\nRainTomorrow\n\n\n\n\n0\n2008-12-01\nAlbury\n13.4\n22.9\n0.6\nNaN\nNaN\nW\n44.0\nW\n...\n71.0\n22.0\n1007.7\n1007.1\n8.0\nNaN\n16.9\n21.8\nNo\nNo\n\n\n1\n2008-12-02\nAlbury\n7.4\n25.1\n0.0\nNaN\nNaN\nWNW\n44.0\nNNW\n...\n44.0\n25.0\n1010.6\n1007.8\nNaN\nNaN\n17.2\n24.3\nNo\nNo\n\n\n2\n2008-12-03\nAlbury\n12.9\n25.7\n0.0\nNaN\nNaN\nWSW\n46.0\nW\n...\n38.0\n30.0\n1007.6\n1008.7\nNaN\n2.0\n21.0\n23.2\nNo\nNo\n\n\n3\n2008-12-04\nAlbury\n9.2\n28.0\n0.0\nNaN\nNaN\nNE\n24.0\nSE\n...\n45.0\n16.0\n1017.6\n1012.8\nNaN\nNaN\n18.1\n26.5\nNo\nNo\n\n\n4\n2008-12-05\nAlbury\n17.5\n32.3\n1.0\nNaN\nNaN\nW\n41.0\nENE\n...\n82.0\n33.0\n1010.8\n1006.0\n7.0\n8.0\n17.8\n29.7\nNo\nNo\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n145455\n2017-06-21\nUluru\n2.8\n23.4\n0.0\nNaN\nNaN\nE\n31.0\nSE\n...\n51.0\n24.0\n1024.6\n1020.3\nNaN\nNaN\n10.1\n22.4\nNo\nNo\n\n\n145456\n2017-06-22\nUluru\n3.6\n25.3\n0.0\nNaN\nNaN\nNNW\n22.0\nSE\n...\n56.0\n21.0\n1023.5\n1019.1\nNaN\nNaN\n10.9\n24.5\nNo\nNo\n\n\n145457\n2017-06-23\nUluru\n5.4\n26.9\n0.0\nNaN\nNaN\nN\n37.0\nSE\n...\n53.0\n24.0\n1021.0\n1016.8\nNaN\nNaN\n12.5\n26.1\nNo\nNo\n\n\n145458\n2017-06-24\nUluru\n7.8\n27.0\n0.0\nNaN\nNaN\nSE\n28.0\nSSE\n...\n51.0\n24.0\n1019.4\n1016.5\n3.0\n2.0\n15.1\n26.0\nNo\nNo\n\n\n145459\n2017-06-25\nUluru\n14.9\nNaN\n0.0\nNaN\nNaN\nNaN\nNaN\nESE\n...\n62.0\n36.0\n1020.2\n1017.9\n8.0\n8.0\n15.0\n20.9\nNo\nNaN\n\n\n\n\n145460 rows × 23 columns\n\n\n\n\ndata.shape\n\n(145460, 23)\n\n\n\ndata.columns = ('dates','location','tempmin','tempmax','rainfall',\n                'evaporation','sunshine','windgustdir','windgustspeed','winddir9am',\n                'winddir3pm','windspeed9am','windspeed3pm','humidity9am','humidity3pm',\n                'pressure9am','pressure3pm','cloud9am','cloud3pm','temp9am',\n                'temp3pm','raintoday','raintomorrow')\n\n\ndata.head()\n\n\n\n\n\n\n\n\ndates\nlocation\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustdir\nwindgustspeed\nwinddir9am\n...\nhumidity9am\nhumidity3pm\npressure9am\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nraintoday\nraintomorrow\n\n\n\n\n0\n2008-12-01\nAlbury\n13.4\n22.9\n0.6\nNaN\nNaN\nW\n44.0\nW\n...\n71.0\n22.0\n1007.7\n1007.1\n8.0\nNaN\n16.9\n21.8\nNo\nNo\n\n\n1\n2008-12-02\nAlbury\n7.4\n25.1\n0.0\nNaN\nNaN\nWNW\n44.0\nNNW\n...\n44.0\n25.0\n1010.6\n1007.8\nNaN\nNaN\n17.2\n24.3\nNo\nNo\n\n\n2\n2008-12-03\nAlbury\n12.9\n25.7\n0.0\nNaN\nNaN\nWSW\n46.0\nW\n...\n38.0\n30.0\n1007.6\n1008.7\nNaN\n2.0\n21.0\n23.2\nNo\nNo\n\n\n3\n2008-12-04\nAlbury\n9.2\n28.0\n0.0\nNaN\nNaN\nNE\n24.0\nSE\n...\n45.0\n16.0\n1017.6\n1012.8\nNaN\nNaN\n18.1\n26.5\nNo\nNo\n\n\n4\n2008-12-05\nAlbury\n17.5\n32.3\n1.0\nNaN\nNaN\nW\n41.0\nENE\n...\n82.0\n33.0\n1010.8\n1006.0\n7.0\n8.0\n17.8\n29.7\nNo\nNo\n\n\n\n\n5 rows × 23 columns\n\n\n\n\n# find categorical variables\ncategorical = [var for var in data.columns if data[var].dtype=='O']\nprint('There are {} categorical variables\\n'.format(len(categorical)))\nprint('The categorical variables are :', categorical)\n\nThere are 7 categorical variables\n\nThe categorical variables are : ['dates', 'location', 'windgustdir', 'winddir9am', 'winddir3pm', 'raintoday', 'raintomorrow']\n\n\n\ndata[categorical]\n\n\n\n\n\n\n\n\ndates\nlocation\nwindgustdir\nwinddir9am\nwinddir3pm\nraintoday\nraintomorrow\n\n\n\n\n0\n2008-12-01\nAlbury\nW\nW\nWNW\nNo\nNo\n\n\n1\n2008-12-02\nAlbury\nWNW\nNNW\nWSW\nNo\nNo\n\n\n2\n2008-12-03\nAlbury\nWSW\nW\nWSW\nNo\nNo\n\n\n3\n2008-12-04\nAlbury\nNE\nSE\nE\nNo\nNo\n\n\n4\n2008-12-05\nAlbury\nW\nENE\nNW\nNo\nNo\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n145455\n2017-06-21\nUluru\nE\nSE\nENE\nNo\nNo\n\n\n145456\n2017-06-22\nUluru\nNNW\nSE\nN\nNo\nNo\n\n\n145457\n2017-06-23\nUluru\nN\nSE\nWNW\nNo\nNo\n\n\n145458\n2017-06-24\nUluru\nSE\nSSE\nN\nNo\nNo\n\n\n145459\n2017-06-25\nUluru\nNaN\nESE\nESE\nNo\nNaN\n\n\n\n\n145460 rows × 7 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145460 entries, 0 to 145459\nData columns (total 23 columns):\n #   Column         Non-Null Count   Dtype  \n---  ------         --------------   -----  \n 0   dates          145460 non-null  object \n 1   location       145460 non-null  object \n 2   tempmin        143975 non-null  float64\n 3   tempmax        144199 non-null  float64\n 4   rainfall       142199 non-null  float64\n 5   evaporation    82670 non-null   float64\n 6   sunshine       75625 non-null   float64\n 7   windgustdir    135134 non-null  object \n 8   windgustspeed  135197 non-null  float64\n 9   winddir9am     134894 non-null  object \n 10  winddir3pm     141232 non-null  object \n 11  windspeed9am   143693 non-null  float64\n 12  windspeed3pm   142398 non-null  float64\n 13  humidity9am    142806 non-null  float64\n 14  humidity3pm    140953 non-null  float64\n 15  pressure9am    130395 non-null  float64\n 16  pressure3pm    130432 non-null  float64\n 17  cloud9am       89572 non-null   float64\n 18  cloud3pm       86102 non-null   float64\n 19  temp9am        143693 non-null  float64\n 20  temp3pm        141851 non-null  float64\n 21  raintoday      142199 non-null  object \n 22  raintomorrow   142193 non-null  object \ndtypes: float64(16), object(7)\nmemory usage: 25.5+ MB\n\n\n\ndata[categorical].isnull().sum()\n\ndates               0\nlocation            0\nwindgustdir     10326\nwinddir9am      10566\nwinddir3pm       4228\nraintoday        3261\nraintomorrow     3267\ndtype: int64\n\n\n\n# view frequency of categorical variables\nfor var in categorical:\n    print(data[var].value_counts())\n\ndates\n2017-06-24    49\n2017-06-23    49\n2017-06-22    49\n2017-06-21    49\n2017-06-20    49\n              ..\n2008-01-27     1\n2008-01-28     1\n2008-01-29     1\n2008-01-30     1\n2008-01-31     1\nName: count, Length: 3436, dtype: int64\nlocation\nCanberra            3436\nSydney              3344\nAdelaide            3193\nDarwin              3193\nHobart              3193\nPerth               3193\nMelbourne           3193\nBrisbane            3193\nAlbury              3040\nMountGinini         3040\nGoldCoast           3040\nWollongong          3040\nMountGambier        3040\nLaunceston          3040\nAliceSprings        3040\nAlbany              3040\nTownsville          3040\nBendigo             3040\nCairns              3040\nBallarat            3040\nPenrith             3039\nNewcastle           3039\nTuggeranong         3039\nPerthAirport        3009\nWilliamtown         3009\nCobar               3009\nBadgerysCreek       3009\nSydneyAirport       3009\nRichmond            3009\nMoree               3009\nCoffsHarbour        3009\nNorfolkIsland       3009\nWaggaWagga          3009\nWitchcliffe         3009\nWatsonia            3009\nDartmoor            3009\nPortland            3009\nSale                3009\nMelbourneAirport    3009\nMildura             3009\nNuriootpa           3009\nWoomera             3009\nPearceRAAF          3009\nWalpole             3006\nNorahHead           3004\nSalmonGums          3001\nNhil                1578\nKatherine           1578\nUluru               1578\nName: count, dtype: int64\nwindgustdir\nW      9915\nSE     9418\nN      9313\nSSE    9216\nE      9181\nS      9168\nWSW    9069\nSW     8967\nSSW    8736\nWNW    8252\nNW     8122\nENE    8104\nESE    7372\nNE     7133\nNNW    6620\nNNE    6548\nName: count, dtype: int64\nwinddir9am\nN      11758\nSE      9287\nE       9176\nSSE     9112\nNW      8749\nS       8659\nW       8459\nSW      8423\nNNE     8129\nNNW     7980\nENE     7836\nNE      7671\nESE     7630\nSSW     7587\nWNW     7414\nWSW     7024\nName: count, dtype: int64\nwinddir3pm\nSE     10838\nW      10110\nS       9926\nWSW     9518\nSSE     9399\nSW      9354\nN       8890\nWNW     8874\nNW      8610\nESE     8505\nE       8472\nNE      8263\nSSW     8156\nNNW     7870\nENE     7857\nNNE     6590\nName: count, dtype: int64\nraintoday\nNo     110319\nYes     31880\nName: count, dtype: int64\nraintomorrow\nNo     110316\nYes     31877\nName: count, dtype: int64\n\n\n\n# view frequency distribution of categorical variables\nfor var in categorical:\n    print(data[var].value_counts()/np.array(len(data),dtype=float))\n\ndates\n2017-06-24    0.000337\n2017-06-23    0.000337\n2017-06-22    0.000337\n2017-06-21    0.000337\n2017-06-20    0.000337\n                ...   \n2008-01-27    0.000007\n2008-01-28    0.000007\n2008-01-29    0.000007\n2008-01-30    0.000007\n2008-01-31    0.000007\nName: count, Length: 3436, dtype: float64\nlocation\nCanberra            0.023622\nSydney              0.022989\nAdelaide            0.021951\nDarwin              0.021951\nHobart              0.021951\nPerth               0.021951\nMelbourne           0.021951\nBrisbane            0.021951\nAlbury              0.020899\nMountGinini         0.020899\nGoldCoast           0.020899\nWollongong          0.020899\nMountGambier        0.020899\nLaunceston          0.020899\nAliceSprings        0.020899\nAlbany              0.020899\nTownsville          0.020899\nBendigo             0.020899\nCairns              0.020899\nBallarat            0.020899\nPenrith             0.020892\nNewcastle           0.020892\nTuggeranong         0.020892\nPerthAirport        0.020686\nWilliamtown         0.020686\nCobar               0.020686\nBadgerysCreek       0.020686\nSydneyAirport       0.020686\nRichmond            0.020686\nMoree               0.020686\nCoffsHarbour        0.020686\nNorfolkIsland       0.020686\nWaggaWagga          0.020686\nWitchcliffe         0.020686\nWatsonia            0.020686\nDartmoor            0.020686\nPortland            0.020686\nSale                0.020686\nMelbourneAirport    0.020686\nMildura             0.020686\nNuriootpa           0.020686\nWoomera             0.020686\nPearceRAAF          0.020686\nWalpole             0.020665\nNorahHead           0.020652\nSalmonGums          0.020631\nNhil                0.010848\nKatherine           0.010848\nUluru               0.010848\nName: count, dtype: float64\nwindgustdir\nW      0.068163\nSE     0.064746\nN      0.064024\nSSE    0.063358\nE      0.063117\nS      0.063028\nWSW    0.062347\nSW     0.061646\nSSW    0.060058\nWNW    0.056730\nNW     0.055837\nENE    0.055713\nESE    0.050681\nNE     0.049038\nNNW    0.045511\nNNE    0.045016\nName: count, dtype: float64\nwinddir9am\nN      0.080833\nSE     0.063846\nE      0.063083\nSSE    0.062643\nNW     0.060147\nS      0.059528\nW      0.058153\nSW     0.057906\nNNE    0.055885\nNNW    0.054860\nENE    0.053870\nNE     0.052736\nESE    0.052454\nSSW    0.052159\nWNW    0.050969\nWSW    0.048288\nName: count, dtype: float64\nwinddir3pm\nSE     0.074508\nW      0.069504\nS      0.068239\nWSW    0.065434\nSSE    0.064616\nSW     0.064306\nN      0.061116\nWNW    0.061006\nNW     0.059192\nESE    0.058470\nE      0.058243\nNE     0.056806\nSSW    0.056070\nNNW    0.054104\nENE    0.054015\nNNE    0.045305\nName: count, dtype: float64\nraintoday\nNo     0.758415\nYes    0.219167\nName: count, dtype: float64\nraintomorrow\nNo     0.758394\nYes    0.219146\nName: count, dtype: float64\n\n\n\n# check for cardinality in categorical variables\nfor var in categorical:\n    print(var, ' contains ', len(data[var].unique()), 'lables')\n\ndates  contains  3436 lables\nlocation  contains  49 lables\nwindgustdir  contains  17 lables\nwinddir9am  contains  17 lables\nwinddir3pm  contains  17 lables\nraintoday  contains  3 lables\nraintomorrow  contains  3 lables\n\n\n\ndata['dates'].dtypes\n\ndtype('O')\n\n\n\ndata['dates'] = pd.to_datetime(data['dates'])\n\n\n# extract year from date\ndata['Year'] = data['dates'].dt.year\ndata['Year'].head()\n\n0    2008\n1    2008\n2    2008\n3    2008\n4    2008\nName: Year, dtype: int32\n\n\n\n# extract month from date\ndata['Month'] = data['dates'].dt.month\ndata['Month'].head()\n\n0    12\n1    12\n2    12\n3    12\n4    12\nName: Month, dtype: int32\n\n\n\n# extract day from date\ndata['Day'] = data['dates'].dt.day\ndata['Day'].head()\n\n0    1\n1    2\n2    3\n3    4\n4    5\nName: Day, dtype: int32\n\n\n\n# drop the original dates variable \ndata.drop('dates', axis=1, inplace = True)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nlocation\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustdir\nwindgustspeed\nwinddir9am\nwinddir3pm\n...\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nraintoday\nraintomorrow\nYear\nMonth\nDay\n\n\n\n\n0\nAlbury\n13.4\n22.9\n0.6\nNaN\nNaN\nW\n44.0\nW\nWNW\n...\n1007.1\n8.0\nNaN\n16.9\n21.8\nNo\nNo\n2008\n12\n1\n\n\n1\nAlbury\n7.4\n25.1\n0.0\nNaN\nNaN\nWNW\n44.0\nNNW\nWSW\n...\n1007.8\nNaN\nNaN\n17.2\n24.3\nNo\nNo\n2008\n12\n2\n\n\n2\nAlbury\n12.9\n25.7\n0.0\nNaN\nNaN\nWSW\n46.0\nW\nWSW\n...\n1008.7\nNaN\n2.0\n21.0\n23.2\nNo\nNo\n2008\n12\n3\n\n\n3\nAlbury\n9.2\n28.0\n0.0\nNaN\nNaN\nNE\n24.0\nSE\nE\n...\n1012.8\nNaN\nNaN\n18.1\n26.5\nNo\nNo\n2008\n12\n4\n\n\n4\nAlbury\n17.5\n32.3\n1.0\nNaN\nNaN\nW\n41.0\nENE\nNW\n...\n1006.0\n7.0\n8.0\n17.8\n29.7\nNo\nNo\n2008\n12\n5\n\n\n\n\n5 rows × 25 columns\n\n\n\n\n# let's do One Hot Encoding of Location variable\n# get k-1 dummy variables after One Hot Encoding \n# preview the dataset with head() method\n\npd.get_dummies(data.location, drop_first=True).head()\n\n\n\n\n\n\n\n\nAlbany\nAlbury\nAliceSprings\nBadgerysCreek\nBallarat\nBendigo\nBrisbane\nCairns\nCanberra\nCobar\n...\nTownsville\nTuggeranong\nUluru\nWaggaWagga\nWalpole\nWatsonia\nWilliamtown\nWitchcliffe\nWollongong\nWoomera\n\n\n\n\n0\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n5 rows × 48 columns\n\n\n\n\nmengubah kolom windgustdir\n\npd.get_dummies(data.windgustdir, drop_first=True,dummy_na=True).head()\n\n\n\n\n\n\n\n\nENE\nESE\nN\nNE\nNNE\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\nNaN\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nmengubah kolom winddir9am\n\npd.get_dummies(data.winddir9am, drop_first=True,dummy_na=True).head()\n\n\n\n\n\n\n\n\nENE\nESE\nN\nNE\nNNE\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\nNaN\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nmengubah kolom winddir3pm\n\npd.get_dummies(data.winddir3pm, drop_first=True,dummy_na=True).head()\n\n\n\n\n\n\n\n\nENE\nESE\nN\nNE\nNNE\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\nNaN\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nmengubah kolom raintoday\n\npd.get_dummies(data.raintoday, drop_first=True,dummy_na=True).head()\n\n\n\n\n\n\n\n\nYes\nNaN\n\n\n\n\n0\nFalse\nFalse\n\n\n1\nFalse\nFalse\n\n\n2\nFalse\nFalse\n\n\n3\nFalse\nFalse\n\n\n4\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nmengubah kolom raintomorrow\n\npd.get_dummies(data.raintomorrow, drop_first=True,dummy_na=True).head()\n\n\n\n\n\n\n\n\nYes\nNaN\n\n\n\n\n0\nFalse\nFalse\n\n\n1\nFalse\nFalse\n\n\n2\nFalse\nFalse\n\n\n3\nFalse\nFalse\n\n\n4\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nmencari data numerik\n\n# find categorical variables\nnumeric = [var for var in data.columns if data[var].dtype!='O']\nprint('There are {} numeric variables\\n'.format(len(numeric)))\nprint('The numeric variables are :', numeric)\n\nThere are 19 numeric variables\n\nThe numeric variables are : ['tempmin', 'tempmax', 'rainfall', 'evaporation', 'sunshine', 'windgustspeed', 'windspeed9am', 'windspeed3pm', 'humidity9am', 'humidity3pm', 'pressure9am', 'pressure3pm', 'cloud9am', 'cloud3pm', 'temp9am', 'temp3pm', 'Year', 'Month', 'Day']\n\n\n\ndata[numeric]\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\npressure9am\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nYear\nMonth\nDay\n\n\n\n\n0\n13.4\n22.9\n0.6\nNaN\nNaN\n44.0\n20.0\n24.0\n71.0\n22.0\n1007.7\n1007.1\n8.0\nNaN\n16.9\n21.8\n2008\n12\n1\n\n\n1\n7.4\n25.1\n0.0\nNaN\nNaN\n44.0\n4.0\n22.0\n44.0\n25.0\n1010.6\n1007.8\nNaN\nNaN\n17.2\n24.3\n2008\n12\n2\n\n\n2\n12.9\n25.7\n0.0\nNaN\nNaN\n46.0\n19.0\n26.0\n38.0\n30.0\n1007.6\n1008.7\nNaN\n2.0\n21.0\n23.2\n2008\n12\n3\n\n\n3\n9.2\n28.0\n0.0\nNaN\nNaN\n24.0\n11.0\n9.0\n45.0\n16.0\n1017.6\n1012.8\nNaN\nNaN\n18.1\n26.5\n2008\n12\n4\n\n\n4\n17.5\n32.3\n1.0\nNaN\nNaN\n41.0\n7.0\n20.0\n82.0\n33.0\n1010.8\n1006.0\n7.0\n8.0\n17.8\n29.7\n2008\n12\n5\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n145455\n2.8\n23.4\n0.0\nNaN\nNaN\n31.0\n13.0\n11.0\n51.0\n24.0\n1024.6\n1020.3\nNaN\nNaN\n10.1\n22.4\n2017\n6\n21\n\n\n145456\n3.6\n25.3\n0.0\nNaN\nNaN\n22.0\n13.0\n9.0\n56.0\n21.0\n1023.5\n1019.1\nNaN\nNaN\n10.9\n24.5\n2017\n6\n22\n\n\n145457\n5.4\n26.9\n0.0\nNaN\nNaN\n37.0\n9.0\n9.0\n53.0\n24.0\n1021.0\n1016.8\nNaN\nNaN\n12.5\n26.1\n2017\n6\n23\n\n\n145458\n7.8\n27.0\n0.0\nNaN\nNaN\n28.0\n13.0\n7.0\n51.0\n24.0\n1019.4\n1016.5\n3.0\n2.0\n15.1\n26.0\n2017\n6\n24\n\n\n145459\n14.9\nNaN\n0.0\nNaN\nNaN\nNaN\n17.0\n17.0\n62.0\n36.0\n1020.2\n1017.9\n8.0\n8.0\n15.0\n20.9\n2017\n6\n25\n\n\n\n\n145460 rows × 19 columns\n\n\n\n\ndata[numeric].duplicated().sum()\n\nnp.int64(1)\n\n\n\ndata[numeric].isnull().sum()\n\ntempmin           1485\ntempmax           1261\nrainfall          3261\nevaporation      62790\nsunshine         69835\nwindgustspeed    10263\nwindspeed9am      1767\nwindspeed3pm      3062\nhumidity9am       2654\nhumidity3pm       4507\npressure9am      15065\npressure3pm      15028\ncloud9am         55888\ncloud3pm         59358\ntemp9am           1767\ntemp3pm           3609\nYear                 0\nMonth                0\nDay                  0\ndtype: int64\n\n\n\nprint(round(data[numeric].describe()),2)\n\n        tempmin   tempmax  rainfall  evaporation  sunshine  windgustspeed  \\\ncount  143975.0  144199.0  142199.0      82670.0   75625.0       135197.0   \nmean       12.0      23.0       2.0          5.0       8.0           40.0   \nstd         6.0       7.0       8.0          4.0       4.0           14.0   \nmin        -8.0      -5.0       0.0          0.0       0.0            6.0   \n25%         8.0      18.0       0.0          3.0       5.0           31.0   \n50%        12.0      23.0       0.0          5.0       8.0           39.0   \n75%        17.0      28.0       1.0          7.0      11.0           48.0   \nmax        34.0      48.0     371.0        145.0      14.0          135.0   \n\n       windspeed9am  windspeed3pm  humidity9am  humidity3pm  pressure9am  \\\ncount      143693.0      142398.0     142806.0     140953.0     130395.0   \nmean           14.0          19.0         69.0         52.0       1018.0   \nstd             9.0           9.0         19.0         21.0          7.0   \nmin             0.0           0.0          0.0          0.0        980.0   \n25%             7.0          13.0         57.0         37.0       1013.0   \n50%            13.0          19.0         70.0         52.0       1018.0   \n75%            19.0          24.0         83.0         66.0       1022.0   \nmax           130.0          87.0        100.0        100.0       1041.0   \n\n       pressure3pm  cloud9am  cloud3pm   temp9am   temp3pm      Year  \\\ncount     130432.0   89572.0   86102.0  143693.0  141851.0  145460.0   \nmean        1015.0       4.0       5.0      17.0      22.0    2013.0   \nstd            7.0       3.0       3.0       6.0       7.0       3.0   \nmin          977.0       0.0       0.0      -7.0      -5.0    2007.0   \n25%         1010.0       1.0       2.0      12.0      17.0    2011.0   \n50%         1015.0       5.0       5.0      17.0      21.0    2013.0   \n75%         1020.0       7.0       7.0      22.0      26.0    2015.0   \nmax         1040.0       9.0       9.0      40.0      47.0    2017.0   \n\n          Month       Day  \ncount  145460.0  145460.0  \nmean        6.0      16.0  \nstd         3.0       9.0  \nmin         1.0       1.0  \n25%         3.0       8.0  \n50%         6.0      16.0  \n75%         9.0      23.0  \nmax        12.0      31.0   2\n\n\n\n\nrainfall,evaporation,windspeed9am,windgustspeed,windspeed3pm\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(3,2,1)\nfig = data.boxplot(column='rainfall')\nfig.set_title('')\nfig.set_ylabel('rainfall')\n\nplt.subplot(3,2,2)\nfig = data.boxplot(column='evaporation')\nfig.set_title('')\nfig.set_ylabel('evaporation')\n\nplt.subplot(3,2,3)\nfig = data.boxplot(column='windspeed9am')\nfig.set_title('')\nfig.set_ylabel('windspeed9am')\n\nplt.subplot(3,2,4)\nfig = data.boxplot(column='windgustspeed')\nfig.set_title('')\nfig.set_ylabel('windgustspeed')\n\nplt.subplot(3,2,5)\nfig = data.boxplot(column='windspeed3pm')\nfig.set_title('')\nfig.set_ylabel('windspeed3pm')\n\nText(0, 0.5, 'windspeed3pm')\n\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(3,2,1)\nfig = data.rainfall.hist(bins=10)\nfig.set_xlabel('rainfall')\nfig.set_ylabel('raintomorrow')\n\nplt.subplot(3,2,2)\nfig = data.evaporation.hist(bins=10)\nfig.set_xlabel('evaporaton')\nfig.set_ylabel('raintomorrow')\n\nplt.subplot(3,2,3)\nfig = data.windspeed9am.hist(bins=10)\nfig.set_xlabel('windspeed9am')\nfig.set_ylabel('raintomorrow')\n\nplt.subplot(3,2,4)\nfig = data.windgustspeed.hist(bins=10)\nfig.set_xlabel('windgustspeed')\nfig.set_ylabel('raintomorrow')\n\nplt.subplot(3,2,5)\nfig = data.windspeed3pm.hist(bins=10)\nfig.set_xlabel('windspeed3pm')\nfig.set_ylabel('raintomorrow')\n\nText(0, 0.5, 'raintomorrow')\n\n\n\n\n\n\n\n\n\n\n# find outliers for rainfall variable\n\nIQR = data.rainfall.quantile(0.75) - data.rainfall.quantile(0.25)\nLower_fence = data.rainfall.quantile(0.25) - (IQR * 3)\nUpper_fence = data.rainfall.quantile(0.75) + (IQR * 3)\nprint('rainfall outliers are values &lt; {lowerboundary} or &gt; {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\nIQR = data.evaporation.quantile(0.75) - data.evaporation.quantile(0.25)\nLower_fence = data.evaporation.quantile(0.25) - (IQR * 3)\nUpper_fence = data.evaporation.quantile(0.75) + (IQR * 3)\nprint('evaporation outliers are values &lt; {lowerboundary} or &gt; {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\nIQR = data.windspeed9am.quantile(0.75) - data.windspeed9am.quantile(0.25)\nLower_fence = data.windspeed9am.quantile(0.25) - (IQR * 3)\nUpper_fence = data.windspeed9am.quantile(0.75) + (IQR * 3)\nprint('windspeed9am outliers are values &lt; {lowerboundary} or &gt; {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\nIQR = data.windgustspeed.quantile(0.75) - data.windgustspeed.quantile(0.25)\nLower_fence = data.windgustspeed.quantile(0.25) - (IQR * 3)\nUpper_fence = data.windgustspeed.quantile(0.75) + (IQR * 3)\nprint('windgustspeed outliers are values &lt; {lowerboundary} or &gt; {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\nIQR = data.windspeed3pm.quantile(0.75) - data.windspeed3pm.quantile(0.25)\nLower_fence = data.windspeed3pm.quantile(0.25) - (IQR * 3)\nUpper_fence = data.windspeed3pm.quantile(0.75) + (IQR * 3)\nprint('windspeed3pm outliers are values &lt; {lowerboundary} or &gt; {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\nrainfall outliers are values &lt; -2.4000000000000004 or &gt; 3.2\nevaporation outliers are values &lt; -11.800000000000002 or &gt; 21.800000000000004\nwindspeed9am outliers are values &lt; -29.0 or &gt; 55.0\nwindgustspeed outliers are values &lt; -20.0 or &gt; 99.0\nwindspeed3pm outliers are values &lt; -20.0 or &gt; 57.0\n\n\n\ndata[numeric].isnull().sum()\n\ntempmin           1485\ntempmax           1261\nrainfall          3261\nevaporation      62790\nsunshine         69835\nwindgustspeed    10263\nwindspeed9am      1767\nwindspeed3pm      3062\nhumidity9am       2654\nhumidity3pm       4507\npressure9am      15065\npressure3pm      15028\ncloud9am         55888\ncloud3pm         59358\ntemp9am           1767\ntemp3pm           3609\nYear                 0\nMonth                0\nDay                  0\ndtype: int64\n\n\n\nx = data.drop(['raintomorrow'], axis=1)\ny = data['raintomorrow']\n\n\n# split x and y info training and testing sets\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n\n\n# check the shape of x_train and x_test\n\nx_train.shape, x_test.shape\n\n((116368, 24), (29092, 24))\n\n\n\n# print percentage of missing values in the numerical variables in training set \n\nfor col in numeric:\n    if x_train[col].isnull().mean()&gt;0:\n        print(col, round(x_train[col].isnull().mean(),4))\n\ntempmin 0.0102\ntempmax 0.0088\nrainfall 0.0225\nevaporation 0.4327\nsunshine 0.4804\nwindgustspeed 0.0706\nwindspeed9am 0.0121\nwindspeed3pm 0.0211\nhumidity9am 0.0185\nhumidity3pm 0.0309\npressure9am 0.1039\npressure3pm 0.1037\ncloud9am 0.385\ncloud3pm 0.4087\ntemp9am 0.0122\ntemp3pm 0.0246\n\n\n\n# impute missing values in x_train and x_test with respective column median in x_train\n\nfor df1 in[x_train, x_test]:\n    for col in numeric:\n        col_median=x_train[col].median()\n        df1[col].fillna(col_median, inplace=True)\n        #print(df1[col])\n\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n/tmp/ipykernel_1983/151397047.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df1[col].fillna(col_median, inplace=True)\n\n\n\nnumeric\n\n['tempmin',\n 'tempmax',\n 'rainfall',\n 'evaporation',\n 'sunshine',\n 'windgustspeed',\n 'windspeed9am',\n 'windspeed3pm',\n 'humidity9am',\n 'humidity3pm',\n 'pressure9am',\n 'pressure3pm',\n 'cloud9am',\n 'cloud3pm',\n 'temp9am',\n 'temp3pm',\n 'Year',\n 'Month',\n 'Day']\n\n\n\nx_train[numeric].isnull().sum()\n\ntempmin          0\ntempmax          0\nrainfall         0\nevaporation      0\nsunshine         0\nwindgustspeed    0\nwindspeed9am     0\nwindspeed3pm     0\nhumidity9am      0\nhumidity3pm      0\npressure9am      0\npressure3pm      0\ncloud9am         0\ncloud3pm         0\ntemp9am          0\ntemp3pm          0\nYear             0\nMonth            0\nDay              0\ndtype: int64\n\n\n\nnp.__version__\n\n'2.1.3'\n\n\n\npd.__version__\n\n'2.2.3'\n\n\n\nx_train[numeric[0]]=x_train[numeric[0]].fillna(x_train[numeric[0]].median())\n\n\nx_train[numeric[0]]\n\n22926     18.8\n80735      9.3\n121764    10.9\n139821    19.3\n1867      15.7\n          ... \n41993     17.8\n97639     12.5\n95939     17.0\n117952    11.9\n43567     12.0\nName: tempmin, Length: 116368, dtype: float64\n\n\n\ndef max_value(df3, variable, top):\n    return np.where(df3[variable]&gt;top, top, df3[variable])\n\nfor df3 in [x_train, x_test]:\n    df3['rainfall'] = max_value(df3, 'rainfall' , 3.2)\n    df3['evaporation'] = max_value(df3, 'evaporation' , 21.8)\n    df3['windspeed9am'] = max_value(df3, 'windspeed9am' , 55)\n    df3['windspeed3pm'] = max_value(df3, 'windspeed3pm', 57)\n    df3['windgustspeed'] = max_value(df3, 'windgustspeed', 99)\n\n\nx_train[numeric].describe()\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\npressure9am\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nYear\nMonth\nDay\n\n\n\n\ncount\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n\n\nmean\n12.190189\n23.203107\n0.670800\n5.093362\n7.982476\n39.973386\n14.029381\n18.687466\n68.950691\n51.605828\n1017.639891\n1015.244946\n4.664092\n4.710728\n16.979454\n21.657195\n2012.767058\n6.395091\n15.731954\n\n\nstd\n6.366893\n7.085408\n1.181512\n2.800200\n2.761639\n13.083633\n8.835596\n8.700618\n18.811437\n20.439999\n6.728234\n6.661517\n2.280687\n2.106040\n6.449641\n6.848293\n2.538401\n3.425451\n8.796931\n\n\nmin\n-8.500000\n-4.800000\n0.000000\n0.000000\n0.000000\n6.000000\n0.000000\n0.000000\n0.000000\n0.000000\n980.500000\n977.100000\n0.000000\n0.000000\n-7.200000\n-5.400000\n2007.000000\n1.000000\n1.000000\n\n\n25%\n7.700000\n18.000000\n0.000000\n4.000000\n8.200000\n31.000000\n7.000000\n13.000000\n57.000000\n37.000000\n1013.500000\n1011.100000\n3.000000\n4.000000\n12.300000\n16.700000\n2011.000000\n3.000000\n8.000000\n\n\n50%\n12.000000\n22.600000\n0.000000\n4.700000\n8.400000\n39.000000\n13.000000\n19.000000\n70.000000\n52.000000\n1017.600000\n1015.200000\n5.000000\n5.000000\n16.700000\n21.100000\n2013.000000\n6.000000\n16.000000\n\n\n75%\n16.800000\n28.200000\n0.600000\n5.200000\n8.600000\n46.000000\n19.000000\n24.000000\n83.000000\n65.000000\n1021.800000\n1019.400000\n6.000000\n6.000000\n21.500000\n26.200000\n2015.000000\n9.000000\n23.000000\n\n\nmax\n31.900000\n48.100000\n3.200000\n21.800000\n14.500000\n99.000000\n55.000000\n57.000000\n100.000000\n100.000000\n1041.000000\n1039.600000\n9.000000\n8.000000\n40.200000\n46.700000\n2017.000000\n12.000000\n31.000000\n\n\n\n\n\n\n\n\n!pip install category_encoders\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: category_encoders in /home/runner/.local/lib/python3.10/site-packages (2.6.4)\nRequirement already satisfied: pandas&gt;=1.0.5 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (2.2.3)\nRequirement already satisfied: scikit-learn&gt;=0.20.0 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (1.5.2)\nRequirement already satisfied: statsmodels&gt;=0.9.0 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (0.14.4)\nRequirement already satisfied: numpy&gt;=1.14.0 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (2.1.3)\nRequirement already satisfied: patsy&gt;=0.5.1 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (1.0.1)\nRequirement already satisfied: scipy&gt;=1.0.0 in /home/runner/.local/lib/python3.10/site-packages (from category_encoders) (1.14.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/runner/.local/lib/python3.10/site-packages (from pandas&gt;=1.0.5-&gt;category_encoders) (2024.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/lib/python3/dist-packages (from pandas&gt;=1.0.5-&gt;category_encoders) (2022.1)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/runner/.local/lib/python3.10/site-packages (from pandas&gt;=1.0.5-&gt;category_encoders) (2.9.0.post0)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in /home/runner/.local/lib/python3.10/site-packages (from scikit-learn&gt;=0.20.0-&gt;category_encoders) (3.5.0)\nRequirement already satisfied: joblib&gt;=1.2.0 in /home/runner/.local/lib/python3.10/site-packages (from scikit-learn&gt;=0.20.0-&gt;category_encoders) (1.4.2)\nRequirement already satisfied: packaging&gt;=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels&gt;=0.9.0-&gt;category_encoders) (24.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/lib/python3/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.0.5-&gt;category_encoders) (1.16.0)\n\n\n\n# encode raintoday variable \n\nimport category_encoders as ce\nencoder = ce.BinaryEncoder(cols=['raintoday'])\nx_train = encoder.fit_transform(x_train)\nx_test = encoder.transform(x_test)\n\n\nx_train.head()\n\n\n\n\n\n\n\n\nlocation\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustdir\nwindgustspeed\nwinddir9am\nwinddir3pm\n...\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nraintoday_0\nraintoday_1\nYear\nMonth\nDay\n\n\n\n\n22926\nNorfolkIsland\n18.8\n23.7\n0.2\n5.0\n7.3\nESE\n52.0\nESE\nESE\n...\n1013.9\n5.0\n7.0\n21.4\n22.2\n0\n1\n2014\n3\n12\n\n\n80735\nWatsonia\n9.3\n24.0\n0.2\n1.6\n10.9\nNE\n48.0\nNNW\nNNE\n...\n1014.6\n3.0\n5.0\n14.3\n23.2\n0\n1\n2016\n10\n6\n\n\n121764\nPerth\n10.9\n22.2\n1.4\n1.2\n9.6\nSW\n26.0\nNaN\nSW\n...\n1014.9\n1.0\n2.0\n16.6\n21.5\n1\n0\n2011\n8\n31\n\n\n139821\nDarwin\n19.3\n29.9\n0.0\n9.2\n11.0\nESE\n43.0\nESE\nE\n...\n1012.1\n1.0\n1.0\n23.2\n29.1\n0\n1\n2010\n6\n11\n\n\n1867\nAlbury\n15.7\n17.6\n3.2\n4.7\n8.4\nE\n20.0\nESE\nE\n...\n1010.5\n8.0\n8.0\n16.5\n17.3\n1\n0\n2014\n4\n10\n\n\n\n\n5 rows × 25 columns\n\n\n\n\nx_train = pd.concat([x_train[numeric], x_train[['raintoday_0', 'raintoday_1']],\n                     pd.get_dummies(x_train.location),\n                     pd.get_dummies(x_train.windgustdir),\n                     pd.get_dummies(x_train.winddir9am),\n                     pd.get_dummies(x_train.winddir3pm)], axis=1)\n\n\nx_train.head()\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\n\n\n\n\n22926\n18.8\n23.7\n0.2\n5.0\n7.3\n52.0\n31.0\n28.0\n74.0\n73.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n80735\n9.3\n24.0\n0.2\n1.6\n10.9\n48.0\n13.0\n24.0\n74.0\n55.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n121764\n10.9\n22.2\n1.4\n1.2\n9.6\n26.0\n0.0\n11.0\n85.0\n47.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n139821\n19.3\n29.9\n0.0\n9.2\n11.0\n43.0\n26.0\n17.0\n44.0\n37.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1867\n15.7\n17.6\n3.2\n4.7\n8.4\n20.0\n11.0\n13.0\n100.0\n100.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n5 rows × 118 columns\n\n\n\n\nx_test = pd.concat([x_test[numeric], x_test[['raintoday_0', 'raintoday_1']],\n                     pd.get_dummies(x_test.location),\n                     pd.get_dummies(x_test.windgustdir),\n                     pd.get_dummies(x_test.winddir9am),\n                     pd.get_dummies(x_test.winddir3pm)], axis=1)\n\n\nx_test\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\n\n\n\n\n138175\n21.9\n39.4\n1.6\n11.2\n11.5\n57.0\n20.0\n33.0\n50.0\n26.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n38638\n20.5\n37.5\n0.0\n9.2\n8.4\n59.0\n17.0\n20.0\n47.0\n22.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n124058\n5.1\n17.2\n0.2\n4.7\n8.4\n50.0\n28.0\n22.0\n68.0\n51.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n99214\n11.9\n16.8\n1.0\n4.7\n8.4\n28.0\n11.0\n13.0\n80.0\n79.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n25097\n7.5\n21.3\n0.0\n4.7\n8.4\n15.0\n2.0\n7.0\n88.0\n52.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n133493\n18.2\n24.4\n3.2\n4.7\n8.4\n44.0\n13.0\n20.0\n85.0\n70.0\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n43818\n9.4\n18.0\n0.0\n4.7\n8.4\n48.0\n26.0\n17.0\n54.0\n37.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n28118\n10.6\n15.4\n3.2\n1.6\n8.4\n28.0\n17.0\n7.0\n90.0\n67.0\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n120179\n18.6\n26.9\n0.0\n4.0\n7.2\n63.0\n28.0\n24.0\n67.0\n53.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n30398\n7.0\n16.8\n0.0\n4.0\n10.7\n39.0\n17.0\n19.0\n66.0\n44.0\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n29092 rows × 118 columns\n\n\n\n\nx_train.describe()\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\npressure3pm\ncloud9am\ncloud3pm\ntemp9am\ntemp3pm\nYear\nMonth\nDay\nraintoday_0\nraintoday_1\n\n\n\n\ncount\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n...\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n\n\nmean\n12.190189\n23.203107\n0.670800\n5.093362\n7.982476\n39.973386\n14.029381\n18.687466\n68.950691\n51.605828\n...\n1015.244946\n4.664092\n4.710728\n16.979454\n21.657195\n2012.767058\n6.395091\n15.731954\n0.242137\n0.780352\n\n\nstd\n6.366893\n7.085408\n1.181512\n2.800200\n2.761639\n13.083633\n8.835596\n8.700618\n18.811437\n20.439999\n...\n6.661517\n2.280687\n2.106040\n6.449641\n6.848293\n2.538401\n3.425451\n8.796931\n0.428379\n0.414010\n\n\nmin\n-8.500000\n-4.800000\n0.000000\n0.000000\n0.000000\n6.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n977.100000\n0.000000\n0.000000\n-7.200000\n-5.400000\n2007.000000\n1.000000\n1.000000\n0.000000\n0.000000\n\n\n25%\n7.700000\n18.000000\n0.000000\n4.000000\n8.200000\n31.000000\n7.000000\n13.000000\n57.000000\n37.000000\n...\n1011.100000\n3.000000\n4.000000\n12.300000\n16.700000\n2011.000000\n3.000000\n8.000000\n0.000000\n1.000000\n\n\n50%\n12.000000\n22.600000\n0.000000\n4.700000\n8.400000\n39.000000\n13.000000\n19.000000\n70.000000\n52.000000\n...\n1015.200000\n5.000000\n5.000000\n16.700000\n21.100000\n2013.000000\n6.000000\n16.000000\n0.000000\n1.000000\n\n\n75%\n16.800000\n28.200000\n0.600000\n5.200000\n8.600000\n46.000000\n19.000000\n24.000000\n83.000000\n65.000000\n...\n1019.400000\n6.000000\n6.000000\n21.500000\n26.200000\n2015.000000\n9.000000\n23.000000\n0.000000\n1.000000\n\n\nmax\n31.900000\n48.100000\n3.200000\n21.800000\n14.500000\n99.000000\n55.000000\n57.000000\n100.000000\n100.000000\n...\n1039.600000\n9.000000\n8.000000\n40.200000\n46.700000\n2017.000000\n12.000000\n31.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 21 columns\n\n\n\n\ncol = x_train.columns\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n\n\nx_train = pd.DataFrame(x_train, columns=[col])\n\n\nx_test = pd.DataFrame(x_test, columns=[col])\n\n\nx_train.describe()\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\n\n\n\n\ncount\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n...\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n116368.000000\n\n\nmean\n0.512133\n0.529359\n0.209625\n0.233640\n0.550516\n0.365305\n0.255080\n0.327850\n0.689507\n0.516058\n...\n0.054078\n0.059123\n0.068447\n0.074771\n0.065224\n0.056055\n0.064786\n0.069323\n0.060309\n0.064958\n\n\nstd\n0.157596\n0.133940\n0.369223\n0.128450\n0.190458\n0.140684\n0.160647\n0.152642\n0.188114\n0.204400\n...\n0.226173\n0.235855\n0.252512\n0.263023\n0.246922\n0.230029\n0.246149\n0.254004\n0.238059\n0.246452\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.400990\n0.431002\n0.000000\n0.183486\n0.565517\n0.268817\n0.127273\n0.228070\n0.570000\n0.370000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n50%\n0.507426\n0.517958\n0.000000\n0.215596\n0.579310\n0.354839\n0.236364\n0.333333\n0.700000\n0.520000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n75%\n0.626238\n0.623819\n0.187500\n0.238532\n0.593103\n0.430108\n0.345455\n0.421053\n0.830000\n0.650000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 118 columns\n\n\n\n\ny_train.fillna(y_train.mode()[0], inplace=True)\ny_test.fillna(y_train.mode()[0], inplace=True)\n\n\n# train a logistic regression model on the training set \nfrom sklearn.linear_model import LogisticRegression\n\n# instantiate the model \nlogreg = LogisticRegression(solver='liblinear', random_state=0)\n\n# fit the model\nlogreg.fit(x_train, y_train)\n\nLogisticRegression(random_state=0, solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(random_state=0, solver='liblinear') \n\n\n\nlogreg.predict(x_test)\n\narray(['No', 'No', 'No', ..., 'Yes', 'No', 'No'], dtype=object)\n\n\n\nx_test\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\n\n\n\n\n0\n0.752475\n0.835539\n0.5000\n0.513761\n0.793103\n0.548387\n0.363636\n0.578947\n0.50\n0.26\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.717822\n0.799622\n0.0000\n0.422018\n0.579310\n0.569892\n0.309091\n0.350877\n0.47\n0.22\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.336634\n0.415879\n0.0625\n0.215596\n0.579310\n0.473118\n0.509091\n0.385965\n0.68\n0.51\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n3\n0.504950\n0.408318\n0.3125\n0.215596\n0.579310\n0.236559\n0.200000\n0.228070\n0.80\n0.79\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n0.396040\n0.493384\n0.0000\n0.215596\n0.579310\n0.096774\n0.036364\n0.122807\n0.88\n0.52\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n29087\n0.660891\n0.551985\n1.0000\n0.215596\n0.579310\n0.408602\n0.236364\n0.350877\n0.85\n0.70\n...\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29088\n0.443069\n0.431002\n0.0000\n0.215596\n0.579310\n0.451613\n0.472727\n0.298246\n0.54\n0.37\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n29089\n0.472772\n0.381853\n1.0000\n0.073394\n0.579310\n0.236559\n0.309091\n0.122807\n0.90\n0.67\n...\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29090\n0.670792\n0.599244\n0.0000\n0.183486\n0.496552\n0.612903\n0.509091\n0.421053\n0.67\n0.53\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29091\n0.383663\n0.408318\n0.0000\n0.183486\n0.737931\n0.354839\n0.309091\n0.333333\n0.66\n0.44\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n29092 rows × 118 columns\n\n\n\n\ndir(logreg)\n\n['C',\n '__annotations__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__sklearn_clone__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_build_request_for_signature',\n '_check_feature_names',\n '_check_n_features',\n '_doc_link_module',\n '_doc_link_template',\n '_doc_link_url_param_generator',\n '_estimator_type',\n '_get_default_requests',\n '_get_doc_link',\n '_get_metadata_request',\n '_get_param_names',\n '_get_tags',\n '_more_tags',\n '_parameter_constraints',\n '_predict_proba_lr',\n '_repr_html_',\n '_repr_html_inner',\n '_repr_mimebundle_',\n '_validate_data',\n '_validate_params',\n 'class_weight',\n 'classes_',\n 'coef_',\n 'decision_function',\n 'densify',\n 'dual',\n 'fit',\n 'fit_intercept',\n 'get_metadata_routing',\n 'get_params',\n 'intercept_',\n 'intercept_scaling',\n 'l1_ratio',\n 'max_iter',\n 'multi_class',\n 'n_features_in_',\n 'n_iter_',\n 'n_jobs',\n 'penalty',\n 'predict',\n 'predict_log_proba',\n 'predict_proba',\n 'random_state',\n 'score',\n 'set_fit_request',\n 'set_params',\n 'set_score_request',\n 'solver',\n 'sparsify',\n 'tol',\n 'verbose',\n 'warm_start']\n\n\n\nlogreg.score(x_test, y_test)\n\n0.8482744397085109\n\n\n\nlogreg.classes_\n\narray(['No', 'Yes'], dtype=object)\n\n\n\nlogreg.coef_.shape\n\n(1, 118)\n\n\n\nlogreg.intercept_\n\narray([-4.39269679])\n\n\n\nx_test\n\n\n\n\n\n\n\n\ntempmin\ntempmax\nrainfall\nevaporation\nsunshine\nwindgustspeed\nwindspeed9am\nwindspeed3pm\nhumidity9am\nhumidity3pm\n...\nNNW\nNW\nS\nSE\nSSE\nSSW\nSW\nW\nWNW\nWSW\n\n\n\n\n0\n0.752475\n0.835539\n0.5000\n0.513761\n0.793103\n0.548387\n0.363636\n0.578947\n0.50\n0.26\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.717822\n0.799622\n0.0000\n0.422018\n0.579310\n0.569892\n0.309091\n0.350877\n0.47\n0.22\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.336634\n0.415879\n0.0625\n0.215596\n0.579310\n0.473118\n0.509091\n0.385965\n0.68\n0.51\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n3\n0.504950\n0.408318\n0.3125\n0.215596\n0.579310\n0.236559\n0.200000\n0.228070\n0.80\n0.79\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n0.396040\n0.493384\n0.0000\n0.215596\n0.579310\n0.096774\n0.036364\n0.122807\n0.88\n0.52\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n29087\n0.660891\n0.551985\n1.0000\n0.215596\n0.579310\n0.408602\n0.236364\n0.350877\n0.85\n0.70\n...\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29088\n0.443069\n0.431002\n0.0000\n0.215596\n0.579310\n0.451613\n0.472727\n0.298246\n0.54\n0.37\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n29089\n0.472772\n0.381853\n1.0000\n0.073394\n0.579310\n0.236559\n0.309091\n0.122807\n0.90\n0.67\n...\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29090\n0.670792\n0.599244\n0.0000\n0.183486\n0.496552\n0.612903\n0.509091\n0.421053\n0.67\n0.53\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n29091\n0.383663\n0.408318\n0.0000\n0.183486\n0.737931\n0.354839\n0.309091\n0.333333\n0.66\n0.44\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n29092 rows × 118 columns",
    "crumbs": [
      "Prakiraan Cuaca"
    ]
  },
  {
    "objectID": "titanic.html",
    "href": "titanic.html",
    "title": "Kapal Titanic",
    "section": "",
    "text": "# imports needed for the script \nimport numpy as np\nimport pandas as pd\nimport re \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\n\n\ntitanic_train = pd.read_csv('titanic_train.csv')\n\n\ntitanic_test = pd.read_csv('titanic_test.csv')\n\nPassengerId = titanic_test['PassengerId']\n\n\ntitanic_train.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\ntitanic_test.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS\n\n\n\n\n\n\n\n\n# Waening: Beware of actually copying the dataframe instead of just referencing it\n# \"original_train = train\" will create a reference to the train variable (changes in 'titanic_train' will apply to 'original_train')\noriginal_train = titanic_train.copy() # Using 'copy()\" allows to clone the dataset, creating a different object with the same values \n\n# Feature engineering steps taken from Sina and Anisotropic, with minor changes to avoid warnings \nfull_data = [titanic_train, titanic_test]\n\n# Feature that tells wheather a passenger had a cabin on the Titanic\ntitanic_train['Has_Cabin'] = titanic_train[\"Cabin\"].apply(lambda x:0 if type(x) == float else 1)\ntitanic_test['Has_Cabin'] = titanic_test[\"Cabin\"].apply(lambda x:0 if type (x) == float else 1)\n\n\ntitanic_train\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n0\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n1\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n0\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n1\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n0\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n1\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\n0\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n1\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n0\n\n\n\n\n891 rows × 13 columns\n\n\n\n\ntitanic_test\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n0\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n0\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n0\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n0\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\nSpector, Mr. Woolf\nmale\nNaN\n0\n0\nA.5. 3236\n8.0500\nNaN\nS\n0\n\n\n414\n1306\n1\nOliva y Ocana, Dona. Fermina\nfemale\n39.0\n0\n0\nPC 17758\n108.9000\nC105\nC\n1\n\n\n415\n1307\n3\nSaether, Mr. Simon Sivertsen\nmale\n38.5\n0\n0\nSOTON/O.Q. 3101262\n7.2500\nNaN\nS\n0\n\n\n416\n1308\n3\nWare, Mr. Frederick\nmale\nNaN\n0\n0\n359309\n8.0500\nNaN\nS\n0\n\n\n417\n1309\n3\nPeter, Master. Michael J\nmale\nNaN\n1\n1\n2668\n22.3583\nNaN\nC\n0\n\n\n\n\n418 rows × 12 columns\n\n\n\n\n# Create new feature FamilySize as a combination of SibSp and Parch \nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\n# Create new feature IsAlone from FamilySize \nfor dataset in full_data:\n    dataset['IsAlone'] = 0 \n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\n\ntitanic_train\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n0\n2\n0\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n1\n2\n0\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n0\n1\n1\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n1\n2\n0\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n0\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n0\n1\n1\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n1\n1\n1\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\n0\n4\n0\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n1\n1\n1\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n0\n1\n1\n\n\n\n\n891 rows × 15 columns\n\n\n\n\ntitanic_test\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n0\n1\n1\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n0\n2\n0\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n0\n1\n1\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n0\n1\n1\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS\n0\n3\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\nSpector, Mr. Woolf\nmale\nNaN\n0\n0\nA.5. 3236\n8.0500\nNaN\nS\n0\n1\n1\n\n\n414\n1306\n1\nOliva y Ocana, Dona. Fermina\nfemale\n39.0\n0\n0\nPC 17758\n108.9000\nC105\nC\n1\n1\n1\n\n\n415\n1307\n3\nSaether, Mr. Simon Sivertsen\nmale\n38.5\n0\n0\nSOTON/O.Q. 3101262\n7.2500\nNaN\nS\n0\n1\n1\n\n\n416\n1308\n3\nWare, Mr. Frederick\nmale\nNaN\n0\n0\n359309\n8.0500\nNaN\nS\n0\n1\n1\n\n\n417\n1309\n3\nPeter, Master. Michael J\nmale\nNaN\n1\n1\n2668\n22.3583\nNaN\nC\n0\n3\n0\n\n\n\n\n418 rows × 14 columns\n\n\n\n\n# Remove all NULLS in the Embarked column \nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n\n# Remove all NULLS in the Fare column \nfor dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(titanic_train['Fare'].median())\n\n# Remove all NULLS in the Age column\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    # Next line has been improved to avoid warning \n    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34\n0\n0\n330911\n7.8292\nNaN\nQ\n0\n1\n1\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47\n1\n0\n363272\n7.0000\nNaN\nS\n0\n2\n0\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62\n0\n0\n240276\n9.6875\nNaN\nQ\n0\n1\n1\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27\n0\n0\n315154\n8.6625\nNaN\nS\n0\n1\n1\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22\n1\n1\n3101298\n12.2875\nNaN\nS\n0\n3\n0\n\n\n\n\n\n\n\n\n# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\n# Group all non-common titles into one single grouping \"Rare\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\nTitle\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34\n0\n0\n330911\n7.8292\nNaN\nQ\n0\n1\n1\nMr\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47\n1\n0\n363272\n7.0000\nNaN\nS\n0\n2\n0\nMrs\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62\n0\n0\n240276\n9.6875\nNaN\nQ\n0\n1\n1\nMr\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27\n0\n0\n315154\n8.6625\nNaN\nS\n0\n1\n1\nMr\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22\n1\n1\n3101298\n12.2875\nNaN\nS\n0\n3\n0\nMrs\n\n\n\n\n\n\n\n\nfor dataset in full_data:\n    # Mapping Sex \n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n    # Mapping Titles\n    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] &gt; 7.91) & (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] &gt; 14.454) & (dataset['Fare'] &lt;= 31), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\n    # Mapping Age\n    dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0 \n    dataset.loc[(dataset['Age'] &gt; 16) & (dataset['Age'] &lt;= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] &gt; 32) & (dataset['Age'] &lt;= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] &gt; 48) & (dataset['Age'] &lt;= 64), 'Age'] = 3 \n    dataset.loc[ dataset['Age'] &gt; 64, 'Age'] ;\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\nTitle\n\n\n\n\n0\n892\n3\nKelly, Mr. James\n1\n2\n0\n0\n330911\n0\nNaN\n2\n0\n1\n1\n1\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\n0\n2\n1\n0\n363272\n0\nNaN\n0\n0\n2\n0\n3\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\n1\n3\n0\n0\n240276\n1\nNaN\n2\n0\n1\n1\n1\n\n\n3\n895\n3\nWirz, Mr. Albert\n1\n1\n0\n0\n315154\n1\nNaN\n0\n0\n1\n1\n1\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\n0\n1\n1\n1\n3101298\n1\nNaN\n0\n0\n3\n0\n3\n\n\n\n\n\n\n\n\ntitanic_test\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\nTitle\n\n\n\n\n0\n892\n3\nKelly, Mr. James\n1\n2\n0\n0\n330911\n0\nNaN\n2\n0\n1\n1\n1\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\n0\n2\n1\n0\n363272\n0\nNaN\n0\n0\n2\n0\n3\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\n1\n3\n0\n0\n240276\n1\nNaN\n2\n0\n1\n1\n1\n\n\n3\n895\n3\nWirz, Mr. Albert\n1\n1\n0\n0\n315154\n1\nNaN\n0\n0\n1\n1\n1\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\n0\n1\n1\n1\n3101298\n1\nNaN\n0\n0\n3\n0\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\nSpector, Mr. Woolf\n1\n2\n0\n0\nA.5. 3236\n1\nNaN\n0\n0\n1\n1\n1\n\n\n414\n1306\n1\nOliva y Ocana, Dona. Fermina\n0\n2\n0\n0\nPC 17758\n3\nC105\n1\n1\n1\n1\n5\n\n\n415\n1307\n3\nSaether, Mr. Simon Sivertsen\n1\n2\n0\n0\nSOTON/O.Q. 3101262\n0\nNaN\n0\n0\n1\n1\n1\n\n\n416\n1308\n3\nWare, Mr. Frederick\n1\n1\n0\n0\n359309\n1\nNaN\n0\n0\n1\n1\n1\n\n\n417\n1309\n3\nPeter, Master. Michael J\n1\n1\n1\n1\n2668\n2\nNaN\n1\n0\n3\n0\n2\n\n\n\n\n418 rows × 15 columns\n\n\n\n\ntitanic_train.drop(['PassengerId','Name','Ticket','Cabin','SibSp'], axis=1, inplace=True)\n\n\ntitanic_train\n\n\n\n\n\n\n\n\nSurvived\nPclass\nSex\nAge\nParch\nFare\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\nTitle\n\n\n\n\n0\n0\n3\n1\n1\n0\n0\n0\n0\n2\n0\n1\n\n\n1\n1\n1\n0\n2\n0\n3\n1\n1\n2\n0\n3\n\n\n2\n1\n3\n0\n1\n0\n1\n0\n0\n1\n1\n4\n\n\n3\n1\n1\n0\n2\n0\n3\n0\n1\n2\n0\n3\n\n\n4\n0\n3\n1\n2\n0\n1\n0\n0\n1\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\n1\n1\n0\n1\n0\n0\n1\n1\n5\n\n\n887\n1\n1\n0\n1\n0\n2\n0\n1\n1\n1\n4\n\n\n888\n0\n3\n0\n1\n2\n2\n0\n0\n4\n0\n4\n\n\n889\n1\n1\n1\n1\n0\n2\n1\n1\n1\n1\n1\n\n\n890\n0\n3\n1\n1\n0\n0\n2\n0\n1\n1\n1\n\n\n\n\n891 rows × 11 columns\n\n\n\n\ntitanic_test=titanic_test.drop(['PassengerId','Name','Ticket','Cabin','SibSp'], axis=1)\n\n\ntitanic_test\n\n\n\n\n\n\n\n\nPclass\nSex\nAge\nParch\nFare\nEmbarked\nHas_Cabin\nFamilySize\nIsAlone\nTitle\n\n\n\n\n0\n3\n1\n2\n0\n0\n2\n0\n1\n1\n1\n\n\n1\n3\n0\n2\n0\n0\n0\n0\n2\n0\n3\n\n\n2\n2\n1\n3\n0\n1\n2\n0\n1\n1\n1\n\n\n3\n3\n1\n1\n0\n1\n0\n0\n1\n1\n1\n\n\n4\n3\n0\n1\n1\n1\n0\n0\n3\n0\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n3\n1\n2\n0\n1\n0\n0\n1\n1\n1\n\n\n414\n1\n0\n2\n0\n3\n1\n1\n1\n1\n5\n\n\n415\n3\n1\n2\n0\n0\n0\n0\n1\n1\n1\n\n\n416\n3\n1\n1\n0\n1\n0\n0\n1\n1\n1\n\n\n417\n3\n1\n1\n1\n2\n1\n0\n3\n0\n2\n\n\n\n\n418 rows × 10 columns\n\n\n\n\ncolormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(titanic_train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n\n\n\n\n\n\n\n\n\nvariable_baru = titanic_train['Title']\n\n\nvariable_baru\n\n0      1\n1      3\n2      4\n3      3\n4      1\n      ..\n886    5\n887    4\n888    4\n889    1\n890    1\nName: Title, Length: 891, dtype: int64\n\n\n\nvariable_baru = titanic_train['Sex']\n\n\nvariable_baru\n\n0      1\n1      0\n2      0\n3      0\n4      1\n      ..\n886    1\n887    0\n888    0\n889    1\n890    1\nName: Sex, Length: 891, dtype: int64\n\n\n\ntitanic_train['FamilySize']\n\n0      2\n1      2\n2      1\n3      2\n4      1\n      ..\n886    1\n887    1\n888    4\n889    1\n890    1\nName: FamilySize, Length: 891, dtype: int64\n\n\n\ntitanic_train['Parch']\n\n0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n886    0\n887    0\n888    2\n889    0\n890    0\nName: Parch, Length: 891, dtype: int64\n\n\n\ntitanic_train[['Title', 'Survived']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n# Since \"Survived\" is a binary class (0 or 1), these metrics grouped by the Title feature represent:\n    # MEAN: survival rate\n    # COUNT: total observations\n    # SUM: people survived\n\n# title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\n\n\n\n\n\n\n\nTitle\nSurvived\n\n\n\n\nmean\ncount\nsum\n\n\n\n\n0\n1\n0.156673\n517\n81\n\n\n1\n2\n0.575000\n40\n23\n\n\n2\n3\n0.793651\n126\n100\n\n\n3\n4\n0.702703\n185\n130\n\n\n4\n5\n0.347826\n23\n8\n\n\n\n\n\n\n\n\ntitanic_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).agg(['mean', 'count', 'sum'])\n# Since Survived is a binary feature, this metrics grouped by the Sex feature represent:\n    # MEAN: survival rate\n    # COUNT: total observations\n    # SUM: people survived\n\n# sex_mapping = {{'female': 0, 'male' 1}}\n\n\n\n\n\n\n\n\nSex\nSurvived\n\n\n\n\nmean\ncount\nsum\n\n\n\n\n0\n0\n0.742038\n314\n233\n\n\n1\n1\n0.188908\n577\n109\n\n\n\n\n\n\n\n\n# Let's use our 'original_train' dataframe to check the sex distribution for each title.\n# We use copy() again to prevent modifications in out original_train dataset\ntitle_and_sex = original_train.copy()[['Name', 'Sex']]\n\n# Create 'Title' feature\ntitle_and_sex['Title'] = title_and_sex['Name'].apply(get_title)\n\n# Map 'Sex' as binary feature \ntitle_and_sex['Sex'] = title_and_sex['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n# Table with 'Sex' distribution grouped by 'Title'\ntitle_and_sex[['Title', 'Sex']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n\n# Since Sex is a binary feature, this metrics grouped by the Title feature represent:\n    # MEAN: percentage of men\n    # COUNT: total observations\n    # SUM: number of men\n\n\n\n\n\n\n\n\nTitle\nSex\n\n\n\n\nmean\ncount\nsum\n\n\n\n\n0\nCapt\n1.000000\n1\n1\n\n\n1\nCol\n1.000000\n2\n2\n\n\n2\nCountess\n0.000000\n1\n0\n\n\n3\nDon\n1.000000\n1\n1\n\n\n4\nDr\n0.857143\n7\n6\n\n\n5\nJonkheer\n1.000000\n1\n1\n\n\n6\nLady\n0.000000\n1\n0\n\n\n7\nMajor\n1.000000\n2\n2\n\n\n8\nMaster\n1.000000\n40\n40\n\n\n9\nMiss\n0.000000\n182\n0\n\n\n10\nMlle\n0.000000\n2\n0\n\n\n11\nMme\n0.000000\n1\n0\n\n\n12\nMr\n1.000000\n517\n517\n\n\n13\nMrs\n0.000000\n125\n0\n\n\n14\nMs\n0.000000\n1\n0\n\n\n15\nRev\n1.000000\n6\n6\n\n\n16\nSir\n1.000000\n1\n1\n\n\n\n\n\n\n\n\n# Define function to calculate Gini Impurity\ndef get_gini_impurity(survived_count, total_count):\n    survival_prob = survived_count/total_count\n    not_survival_prob = (1 - survival_prob)\n    random_observation_survived_prob = survival_prob\n    random_observation_not_survived_prob = (1 - random_observation_survived_prob)\n    mislabelling_survived_prob = not_survival_prob * random_observation_survived_prob\n    mislabelling_not_survived_prob = survival_prob * random_observation_not_survived_prob\n    gini_impurity = mislabelling_survived_prob + mislabelling_not_survived_prob\n    return gini_impurity\n\n\n# GIni Impurity of starting node\ngini_impurity_starting_node = get_gini_impurity(342, 891)\ngini_impurity_starting_node\n\n0.47301295786144265\n\n\n\n# Gini Impurity decrease if node splited for 'female' observations\ngini_impurity_women = get_gini_impurity(233, 314)\ngini_impurity_women\n\n0.3828350034484158\n\n\n\n# Gini Impurity decrease of node for 'male' observations\ngini_impurity_men = get_gini_impurity(109, 577)\ngini_impurity_men\n\n0.3064437162277843\n\n\n\n# Gini Impurity decrease if node splited by Sex\nmen_weight = 577/891\nwomen_weight = 314/891\nweighted_gini_impurity_sex_split = (gini_impurity_men * men_weight) + (gini_impurity_women * women_weight)\n\nsex_gini_decrease = weighted_gini_impurity_sex_split - gini_impurity_starting_node\nsex_gini_decrease\n\n-0.13964795747285214\n\n\n\n# Gini Impurity decrease of node for observations with Title == 1 == Mr\ngini_impurity_title_1 = get_gini_impurity(81, 517)\ngini_impurity_title_1\n\n0.26425329886377663\n\n\n\n# Gini Impurity decrease if node splited for observations with Title != 1 != Mr\ngini_impurity_title_others = get_gini_impurity(261, 374)\ngini_impurity_title_others\n\n0.42170207898424317\n\n\n\n# Gini Impurity decrease if node splited nfor observations with Title == 1 == Mr\ntitle_1_weight = 517/891\ntitle_others_weight = 374/891\nweighted_gini_impurity_title_split = (gini_impurity_title_1 * title_1_weight) + (gini_impurity_title_others * title_others_weight)\n\ntitle_gini_decrease = weighted_gini_impurity_title_split - gini_impurity_starting_node\ntitle_gini_decrease\n\n-0.14267004758907514\n\n\nIn the case of decision trees, the ‘max_depth’ parameter determines the maximum number of attributes the model is going to use for each prediction (up to the number of available features in the dataset)\n\ncv = KFold(n_splits=10)            # Desired number of Cross Validation folds\naccuracies = list()\nmax_attributes = len(list(titanic_test))\ndepth_range = range(1, max_attributes + 1)\n\n# Testing max_depths from 1 to max attributes\n# Uncomment prints for details about each Cross Validation pass\nfor depth in depth_range:\n    fold_accuracy = []\n    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n    # print(\"Current max depth: \", depth, \"\\n\")\n    for train_fold, valid_fold in cv.split(titanic_train):\n        f_train = titanic_train.loc[train_fold] # Extract train data with cv indices\n        f_valid = titanic_train.loc[valid_fold] # Extract valid data with cv indices\n\n        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1),\n                               y = f_train[\"Survived\"]) # We fit the model with the fold train data\n        valid_acc = model.score(X = f_valid.drop(['Survived'], axis=1),\n                                y = f_valid[\"Survived\"])# We calculate accuracy with the fold validation data\n        fold_accuracy.append(valid_acc)\n\n    avg = sum(fold_accuracy)/len(fold_accuracy)\n    accuracies.append(avg)\n    # print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n    # print(\"Average accuracy: \", avg)\n    # print(\"\\n\")\n    \n# Just to show results conveniently\ndf = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\ndf = df[[\"Max Depth\", \"Average Accuracy\"]]\nprint(df.to_string(index=False))\n\n Max Depth  Average Accuracy\n         1          0.782285\n         2          0.799189\n         3          0.828277\n         4          0.819288\n         5          0.812647\n         6          0.820487\n         7          0.810375\n         8          0.818227\n         9          0.820462\n        10          0.817104\n\n\n\nCreate Numpy arrays of train, test and target (Survived) dataframes to feed into our models\ny_train = titanic_train[‘Survived’] x_train = titanic_train.drop([‘Survived’], axis=1).values x_test = titanic_test.values\n\n\nCreate Decision Tree with max_depth = 3\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 3) decision_tree.fit(x_train, y_train)\n\n\nPredicting results for test dataset\ny_pred = decision_tree.predict(x_test) submission = pd.DataFrame({ “PassengerId”: PassengerId, “Survived”: y_pred }) submission.to_csv(‘submission.csv’, index=False)",
    "crumbs": [
      "Kapal Titanic"
    ]
  }
]